.\" Automatically generated by Pandoc 2.17.0.1
.\"
.TH "BARMAN-CLOUD-WAL-ARCHIVE" "1" "January 21, 2022" "Barman User manuals" "Version 2.18"
.hy
.SH NAME
.PP
barman-cloud-wal-archive - Archive PostgreSQL WAL files in the Cloud
using \f[C]archive_command\f[R]
.SH SYNOPSIS
.PP
barman-cloud-wal-archive [\f[I]OPTIONS\f[R]] \f[I]DESTINATION_URL\f[R]
\f[I]SERVER_NAME\f[R] \f[I]WAL_PATH\f[R]
.SH DESCRIPTION
.PP
This script can be used in the \f[C]archive_command\f[R] of a PostgreSQL
server to ship WAL files to the Cloud.
Currently AWS S3 and Azure Blob Storage are supported.
.PP
Note: If you are running python 2 or older unsupported versions of
python 3 then avoid the compression options \f[C]--gzip\f[R] or
\f[C]--bzip2\f[R] as barman-cloud-wal-restore is unable to restore
gzip-compressed WALs on python < 3.2 or bzip2-compressed WALs on python
< 3.3.
.PP
This script and Barman are administration tools for disaster recovery of
PostgreSQL servers written in Python and maintained by EnterpriseDB.
.SH POSITIONAL ARGUMENTS
.TP
DESTINATION_URL
URL of the cloud destination, such as a bucket in AWS S3.
For example: \f[C]s3://BUCKET_NAME/path/to/folder\f[R] (where
\f[C]BUCKET_NAME\f[R] is the bucket you have created in AWS).
.TP
SERVER_NAME
the name of the server as configured in Barman.
.TP
WAL_PATH
the value of the `%p' keyword (according to `archive_command').
.SH OPTIONS
.TP
-h, \[en]help
show a help message and exit
.TP
-V, \[en]version
show program\[cq]s version number and exit
.TP
-v, \[en]verbose
increase output verbosity (e.g., -vv is more than -v)
.TP
-q, \[en]quiet
decrease output verbosity (e.g., -qq is less than -q)
.TP
-t, \[en]test
test connectivity to the cloud destination and exit
.TP
-z, \[en]gzip
gzip-compress the WAL while uploading to the cloud (should not be used
with python < 3.2)
.TP
-j, \[en]bzip2
bzip2-compress the WAL while uploading to the cloud (should not be used
with python < 3.3)
.TP
\[en]snappy
snappy-compress the WAL while uploading to the cloud (requires optional
python-snappy library and should not be used with python < 3.3)
.TP
\[en]cloud-provider {aws-s3,azure-blob-storage}
the cloud provider to which the backup should be uploaded
.TP
\[en]tags KEY1,VALUE1 KEY2,VALUE2 \&...
A space-separated list of comma-separated key-value pairs representing
tags to be added to each WAL file archived to cloud storage.
.TP
\[en]history-tags KEY1,VALUE1 KEY2,VALUE2 \&...
A space-separated list of comma-separated key-value pairs representing
tags to be added to each history file archived to cloud storage.
If this is provided alongside the \f[C]--tags\f[R] option then the value
of \f[C]--history-tags\f[R] will be used in place of \f[C]--tags\f[R]
for history files.
All other WAL files will continue to be tagged with the value of
\f[C]--tags\f[R].
.TP
-P, \[en]profile
profile name (e.g.\ INI section in AWS credentials file)
.TP
\[en]endpoint-url
override the default S3 URL construction mechanism by specifying an
endpoint.
.TP
-e, \[en]encryption
the encryption algorithm used when storing the uploaded data in S3
Allowed values: `AES256'|`aws:kms'
.TP
\[en]encryption-scope
the name of an encryption scope defined in the Azure Blob Storage
service which is to be used to encrypt the data in Azure
.TP
\[en]credential {azure-cli,managed-identity}
optionally specify the type of credential to use when authenticating
with Azure Blob Storage.
If omitted then the credential will be obtained from the environment.
If no credentials can be found in the environment then the default Azure
authentication flow will be used.
.TP
\[en]max-block-size SIZE
the chunk size to be used when uploading an object to Azure Blob Storage
via the concurrent chunk method (default: 4MB).
.TP
\[en]max-concurrency CONCURRENCY
the maximum number of chunks to be uploaded concurrently to Azure Blob
Storage (default: 1).
Whether the maximum concurrency is achieved depends on the values of
\[en]max-block-size (should be less than or equal to
\f[C]WAL segment size after compression / max_concurrency\f[R]) and
\[en]max-single-put-size (must be less than WAL segment size after
compression).
.TP
\[en]max-single-put-size SIZE
maximum size for which the Azure client will upload an object to Azure
Blob Storage in a single request (default: 64MB).
If this is set lower than the WAL segment size after any applied
compression then the concurrent chunk upload method for WAL archiving
will be used.
.SH REFERENCES
.PP
For Boto:
.IP \[bu] 2
https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html
.PP
For AWS:
.IP \[bu] 2
http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-set-up.html
.IP \[bu] 2
http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html.
.PP
For Azure Blob Storage:
.IP \[bu] 2
https://docs.microsoft.com/en-us/azure/storage/blobs/authorize-data-operations-cli#set-environment-variables-for-authorization-parameters
.IP \[bu] 2
https://docs.microsoft.com/en-us/python/api/azure-storage-blob/?view=azure-python
.SH DEPENDENCIES
.PP
If using \f[C]--cloud-provider=aws-s3\f[R]:
.IP \[bu] 2
boto3
.PP
If using \f[C]--cloud-provider=azure-blob-storage\f[R]:
.IP \[bu] 2
azure-storage-blob
.IP \[bu] 2
azure-identity (optional, if you wish to use DefaultAzureCredential)
.SH EXIT STATUS
.TP
0
Success
.TP
1
The WAL archive operation was not successful
.TP
2
The connection to the cloud provider failed
.TP
3
There was an error in the command input
.TP
Other non-zero codes
Failure
.SH SEE ALSO
.PP
This script can be used in conjunction with
\f[C]pre_archive_retry_script\f[R] to relay WAL files to S3, as follows:
.IP
.nf
\f[C]
pre_archive_retry_script = \[aq]barman-cloud-wal-archive [*OPTIONS*] *DESTINATION_URL* ${BARMAN_SERVER}\[aq]
\f[R]
.fi
.SH BUGS
.PP
Barman has been extensively tested, and is currently being used in
several production environments.
However, we cannot exclude the presence of bugs.
.PP
Any bug can be reported via the Github issue tracker.
.SH RESOURCES
.IP \[bu] 2
Homepage: <http://www.pgbarman.org/>
.IP \[bu] 2
Documentation: <http://docs.pgbarman.org/>
.IP \[bu] 2
Professional support: <http://www.enterprisedb.com/>
.SH COPYING
.PP
Barman is the property of EnterpriseDB UK Limited and its code is
distributed under GNU General Public License v3.
.PP
\[co] Copyright EnterpriseDB UK Limited 2011-2022
.SH AUTHORS
EnterpriseDB <http://www.enterprisedb.com>.
